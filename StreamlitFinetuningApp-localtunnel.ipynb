{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyMUwh6OW9ftfrbFewVElxoA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/maxreynolds/Pattern-Cloud/blob/main/StreamlitFinetuningApp-localtunnel.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "JihJ7XZ2PddX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "adbed749-bfb3-4f67-ad19-69c7e684e63b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.4/8.4 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.6/190.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCloning into 'diffusers'...\n",
            "remote: Enumerating objects: 43209, done.\u001b[K\n",
            "remote: Counting objects: 100% (727/727), done.\u001b[K\n",
            "remote: Compressing objects: 100% (215/215), done.\u001b[K\n",
            "remote: Total 43209 (delta 561), reused 611 (delta 482), pack-reused 42482\u001b[K\n",
            "Receiving objects: 100% (43209/43209), 28.03 MiB | 22.11 MiB/s, done.\n",
            "Resolving deltas: 100% (31982/31982), done.\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.0/302.0 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for diffusers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.1/53.1 kB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m108.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m116.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m14.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m30.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "tensorflow 2.14.0 requires tensorboard<2.15,>=2.14, but you have tensorboard 2.15.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m21.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m243.9/243.9 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!cd /content/\n",
        "!pip install -q streamlit\n",
        "!git clone https://github.com/huggingface/diffusers.git\n",
        "!pip install -q ./diffusers\n",
        "!pip install -q  -U -r /content/diffusers/examples/text_to_image/requirements.txt\n",
        "!pip install -q wandb"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!accelerate config default --mixed_precision fp16"
      ],
      "metadata": {
        "id": "GDgEQ7djapZp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "acd722e7-eb96-4765-f8ce-6e16577a396e"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "accelerate configuration saved at /root/.cache/huggingface/accelerate/default_config.yaml\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "wandb.login()"
      ],
      "metadata": {
        "id": "QhGH6ifAabXA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "v80zt9Nb6CIU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Making directories for multipage Streamlit applicaiton files and storing user images\n",
        "!mkdir /content/pages\n",
        "!mkdir /content/user_images\n",
        "!ls"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuuhXaihYnFw",
        "outputId": "8934ca0f-7c18-45c8-908b-a723d8610ad2"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "diffusers  pages  sample_data  user_images\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/Upload.py\n",
        "from diffusers import StableDiffusionPipeline\n",
        "from datasets import load_dataset\n",
        "\n",
        "import streamlit as st\n",
        "import torch\n",
        "\n",
        "from PIL import Image\n",
        "import csv\n",
        "import os\n",
        "\n",
        "def delete_files_in_directory(directory_path):\n",
        "   try:\n",
        "     files = os.listdir(directory_path)\n",
        "     for file in files:\n",
        "       file_path = os.path.join(directory_path, file)\n",
        "       if os.path.isfile(file_path):\n",
        "         os.remove(file_path)\n",
        "   except OSError:\n",
        "     print(\"Error occurred while deleting files.\")\n",
        "\n",
        "image_set = []\n",
        "image_set = st.file_uploader(\"Upload a folder of your training dataset Images:\",\n",
        "    type=[\"png\"], accept_multiple_files=True) # TODO: expand to type=[\"png\",\"jpg\",\"jpeg\"]]... need to update metadata.csv writer code to check for filetype\n",
        "\n",
        "if image_set is not None:\n",
        "    #st.write('Scroll down for next steps')\n",
        "    st.image(image_set, width=128)\n",
        "\n",
        "if st.button('Upload these Images as your Training Dataset', type=\"primary\", use_container_width=True):\n",
        "    placeholder = st.empty()\n",
        "    placeholder.text(\"Formatting images...\")\n",
        "    for idx, image in enumerate(image_set):\n",
        "      im = Image.open(image)\n",
        "      im.save(f\"/content/user_images/image{idx}.png\")\n",
        "    num_images = len(image_set)\n",
        "    my_label = \"<r4nd0m-l4b3l>\"\n",
        "    with open('/content/user_images/metadata.csv', 'w', newline='') as csvfile:\n",
        "      spamwriter = csv.writer(csvfile, delimiter=' ',\n",
        "                            quotechar='|', quoting=csv.QUOTE_MINIMAL)\n",
        "      spamwriter.writerow(['file_name,text'])\n",
        "      for j in range(num_images):\n",
        "        spamwriter.writerow([f'image{j}.png,'] + [my_label])\n",
        "    placeholder.text('Loading dataset...')\n",
        "    dataset = load_dataset(\"imagefolder\", data_dir=\"/content/user_images\", drop_labels=True)\n",
        "    placeholder.text('Pushing to Hub...')\n",
        "    dataset.push_to_hub(\"MaxReynolds/MyPatternDataset\", private=False)\n",
        "    placeholder.text('Upload complete!')\n",
        "    #removing image files here\n",
        "    delete_files_in_directory('/content/user_images')\n"
      ],
      "metadata": {
        "id": "BabENL7sP2xB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd87c30a-1037-4801-e2cd-450e470c1f39"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/Upload.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/pages/1Train.py\n",
        "import streamlit as st\n",
        "import subprocess\n",
        "\n",
        "# should use this function at some point to remove pre-existing model from directory if it exists\n",
        "def delete_files_in_directory(directory_path):\n",
        "   try:\n",
        "     files = os.listdir(directory_path)\n",
        "     for file in files:\n",
        "       file_path = os.path.join(directory_path, file)\n",
        "       if os.path.isfile(file_path):\n",
        "         os.remove(file_path)\n",
        "   except OSError:\n",
        "     print(\"Error occurred while deleting files.\")\n",
        "\n",
        "num_train_steps = st.slider('Select the number of steps for your training process:', 0, 450, 250)\n",
        "st.write('#')\n",
        "\n",
        "if st.button('Start Training on your Dataset', type=\"primary\", use_container_width=True):\n",
        "  st.write('Training...')\n",
        "  subprocess.run([\"accelerate\", \"launch\", \"diffusers/examples/text_to_image/train_text_to_image.py\",\n",
        "    \"--pretrained_model_name_or_path=CompVis/stable-diffusion-v1-4\",\n",
        "    \"--dataset_name=MaxReynolds/MyPatternDataset\",\n",
        "    \"--use_ema\",\n",
        "    \"--resolution=512\",\n",
        "    \"--center_crop\",\n",
        "    \"--random_flip\",\n",
        "    \"--train_batch_size=1\",\n",
        "    \"--gradient_accumulation_steps=4\",\n",
        "    \"--gradient_checkpointing\",\n",
        "    f\"--max_train_steps={num_train_steps}\",\n",
        "    \"--learning_rate=1e-05\",\n",
        "    \"--max_grad_norm=1\",\n",
        "    \"--checkpointing_steps=100000\",\n",
        "    \"--lr_scheduler=constant\",\n",
        "    \"--lr_warmup_steps=0\",\n",
        "    \"--push_to_hub\",\n",
        "    \"--output_dir=MaxReynolds/MyPatternModel\", #Can probably come up for a better name for this directory if not pushing to HF Hub (aka /content/models/)\n",
        "    \"--validation_prompt=,<r4nd0m-l4b3l>\",\n",
        "    \"--report_to=wandb\",\n",
        "    \"--seed=1337\"])\n",
        "  st.write('Training complete!')\n",
        "\n"
      ],
      "metadata": {
        "id": "PV_dnAFVb_DL",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b216070f-5d54-4481-e671-b75f0d30c37c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/pages/1Train.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile /content/pages/2Generate.py\n",
        "from diffusers import StableDiffusionPipeline\n",
        "import torch\n",
        "from PIL import Image\n",
        "\n",
        "import streamlit as st\n",
        "\n",
        "if st.button('Generate some Images', type=\"primary\", use_container_width=True):\n",
        "  model_path = \"MaxReynolds/MyPatternModel\"\n",
        "  pipe = StableDiffusionPipeline.from_pretrained(model_path, torch_dtype=torch.float16)\n",
        "  pipe.to(\"cuda\")\n",
        "  my_prompt = \"<r4nd0m-l4b3l>\"\n",
        "  num_images = 8\n",
        "  # Run inference using above prompt to acquire some number of images\n",
        "  all_images = [pipe(prompt=my_prompt).images[0] for i in range(num_images)]\n",
        "  col1, col2, col3, col4 = st.columns(4)\n",
        "  with col1:\n",
        "    st.image(all_images[0])\n",
        "    st.image(all_images[4])\n",
        "  with col2:\n",
        "    st.image(all_images[1])\n",
        "    st.image(all_images[5])\n",
        "  with col3:\n",
        "    st.image(all_images[2])\n",
        "    st.image(all_images[6])\n",
        "  with col4:\n",
        "    st.image(all_images[3])\n",
        "    st.image(all_images[7])\n"
      ],
      "metadata": {
        "id": "miAe1_GVvu7M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "42a78b81-84dc-48c5-9901-50f7bddd309f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Overwriting /content/pages/2Generate.py\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!npm install -q localtunnel"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L4hEd7fWePKS",
        "outputId": "0dedad46-97cd-42ba-c531-20f7b48550d2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K\u001b[?25h\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35msaveError\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m \u001b[0m\u001b[35menoent\u001b[0m ENOENT: no such file or directory, open '/content/package.json'\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No description\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No repository field.\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No README data\n",
            "\u001b[0m\u001b[37;40mnpm\u001b[0m \u001b[0m\u001b[30;43mWARN\u001b[0m\u001b[35m\u001b[0m content No license field.\n",
            "\u001b[0m\n",
            "+ localtunnel@2.0.2\n",
            "added 22 packages from 22 contributors and audited 22 packages in 1.171s\n",
            "\n",
            "3 packages are looking for funding\n",
            "  run `npm fund` for details\n",
            "\n",
            "found \u001b[92m0\u001b[0m vulnerabilities\n",
            "\n",
            "\u001b[K\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!streamlit run /content/Upload.py &>/content/logs.txt &"
      ],
      "metadata": {
        "id": "l7A6KetHP04i"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!npx localtunnel --port 8501 & curl ipv4.icanhazip.com"
      ],
      "metadata": {
        "id": "VGBC6VycPwRB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb299922-0414-4aa7-e5c9-22b7a112061e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "35.221.132.21\n",
            "\u001b[K\u001b[?25hnpx: installed 22 in 1.188s\n",
            "your url is: https://wet-suns-drum.loca.lt\n"
          ]
        }
      ]
    }
  ]
}